reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
vReg   <- var(reg.comp$diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(reg.comp$diff)
# Form objective
return(mom1/v1 + mom5/v5 + momReg/vReg)
}
myPars <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end]
system.time(opt <- optim(myPars, moment.dist.pops, method = "Nelder-Mead", control = list(maxit = 2)))
moment.dist.pops <- function(myPars){
# Have t.n x y.n = 6400 parameters to estimate.
myEst <- data.frame(record.ids, eli = myPars)
# Form regression-based moments
reg.comp <- merge(pred_ty[, c("t.u", "y", "eli.hat")], myEst, by = c("t.u", "y"), all.y = T)
reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
vReg   <- var(reg.comp$diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(reg.comp$diff)
# Form objective
return( momReg/vReg)
}
myPars <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end]
system.time(opt <- optim(myPars, moment.dist.pops, method = "Nelder-Mead", control = list(maxit = 2)))
moment.dist.pops(myPars)
init <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end]
moment.dist.pops(init)
moment.dist.pops(init)
opt <- optim(init, moment.dist.pops, method = "Nelder-Mead", control = list(maxit = 2))
opt <- optim(init, moment.dist.pops, method = "Nelder-Mead") #  control = list(maxit = 2)
opt <- optim(init, moment.dist.pops, method = "CG")
init
init
init <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end][10]
init <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end][1:10]
record.ids <- pred_ty[pred_ty$y %in% y.start:y.end, c("t.u", "y")][1:10]
record.ids <- pred_ty[pred_ty$y %in% y.start:y.end, c("t.u", "y")][1:10]
record.ids <- pred_ty[pred_ty$y %in% y.start:y.end, c("t.u", "y")]
record.ids <- record.ids[1:10,]
moment.dist.pops <- function(myPars){
# Have t.n x y.n = 6400 parameters to estimate.
myEst <- data.frame(record.ids, eli = myPars)
# Form regression-based moments
reg.comp <- merge(pred_ty[, c("t.u", "y", "eli.hat")], myEst, by = c("t.u", "y"), all.y = T)
reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
vReg   <- var(reg.comp$diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(reg.comp$diff)
# Form objective
return( momReg/vReg)
}
init <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end][1:10]
record.ids <- pred_ty[pred_ty$y %in% y.start:y.end, c("t.u", "y")]
record.ids <- record.ids[1:10,]
moment.dist.pops(init)
opt <- optim(init, moment.dist.pops, method = "CG")
opt
init <- rep(0, 10)
init
opt <- optim(init, moment.dist.pops, method = "CG")
system.time(opt <- optim(init, moment.dist.pops, method = "Nelder-Mead", control = list(maxit = 2)))
opt
system.time(opt <- optim(init, moment.dist.pops, method = "Nelder-Mead", control = list(maxit = 100)))
opt
pred_ty$eli.hat[pred_ty$y %in% y.start:y.end][1:10]
pred_sub <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end]
pred_sub <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end][1:10]
pred_sub
init <- rep(0, 10)
moment.dist.pops <- function(myPars){
# Have t.n x y.n = 6400 parameters to estimate.
#myEst <- data.frame(record.ids, eli = myPars)
# Form regression-based moments
#reg.comp <- merge(pred_ty[, c("t.u", "y", "eli.hat")], myEst, by = c("t.u", "y"), all.y = T)
#reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
diff <- pred_sub$eli.hat - myPars
vReg   <- var(diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(diff)
# Form objective
return( momReg/vReg)
}
system.time(opt <- optim(init, moment.dist.pops, method = "Nelder-Mead", control = list(maxit = 100)))
moment.dist.pops <- function(myPars){
# Have t.n x y.n = 6400 parameters to estimate.
#myEst <- data.frame(record.ids, eli = myPars)
# Form regression-based moments
#reg.comp <- merge(pred_ty[, c("t.u", "y", "eli.hat")], myEst, by = c("t.u", "y"), all.y = T)
#reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
diff <- pred_sub - myPars
vReg   <- var(diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(diff)
# Form objective
return( momReg/vReg)
}
system.time(opt <- optim(init, moment.dist.pops, method = "Nelder-Mead", control = list(maxit = 100)))
opt
opt <- optim(init, moment.dist.pops, method = "Nelder-Mead") #  control = list(maxit = 2)
opt
pred_sub
init
diff <- pred_sub - myPars
moment.dist.pops <- function(myPars){
# Have t.n x y.n = 6400 parameters to estimate.
#myEst <- data.frame(record.ids, eli = myPars)
# Form regression-based moments
#reg.comp <- merge(pred_ty[, c("t.u", "y", "eli.hat")], myEst, by = c("t.u", "y"), all.y = T)
#reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
diff <- (pred_sub - myPars)^2
vReg   <- var(diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(diff)
# Form objective
return( momReg/vReg)
}
opt <- optim(init, moment.dist.pops, method = "Nelder-Mead") #  control = list(maxit = 2)
opt
diff
myPars <- init
init
diff <- (pred_sub - myPars)^2
diff
vReg   <- var(diff)
vReg
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
vReg
momReg <- sum(diff)
momReg
momReg/vReg
moment.dist.pops <- function(myPars){
# Have t.n x y.n = 6400 parameters to estimate.
#myEst <- data.frame(record.ids, eli = myPars)
# Form regression-based moments
#reg.comp <- merge(pred_ty[, c("t.u", "y", "eli.hat")], myEst, by = c("t.u", "y"), all.y = T)
#reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
diff <- (pred_sub - myPars)^2
vReg   <- var(diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(diff)
# Form objective
return( momReg) # /vReg
}
opt <- optim(init, moment.dist.pops, method = "Nelder-Mead") #  control = list(maxit = 2)
opt
pred_sub
opt <- optim(init, moment.dist.pops, method = "CG")
opt
pred_sub
opt <- optim(init, moment.dist.pops, method = "Nelder-Mead") #  control = list(maxit = 2)
opt
moment.dist.pops <- function(myPars){
# Have t.n x y.n = 6400 parameters to estimate.
#myEst <- data.frame(record.ids, eli = myPars)
# Form regression-based moments
#reg.comp <- merge(pred_ty[, c("t.u", "y", "eli.hat")], myEst, by = c("t.u", "y"), all.y = T)
#reg.comp$diff <- (reg.comp$eli.hat - reg.comp$eli)^2
diff <- (pred - myPars)^2
vReg   <- var(diff)
vReg   <- ifelse(is.na(vReg) | vReg == 0, 1, vReg)
momReg <- sum(diff)
# Form objective
return( momReg) # /vReg
}
pred <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end]
#init <- pred_ty$eli.hat[pred_ty$y %in% y.start:y.end]
init <- rep(0, length(pred))
#record.ids <- pred_ty[pred_ty$y %in% y.start:y.end, c("t.u", "y")]
#record.ids <- record.ids[1:10,]
moment.dist.pops(init)
system.time(opt <- optim(init, moment.dist.pops, method = "Nelder-Mead")) # control = list(maxit = 100)
opt
system.time(opt <- optim(init, moment.dist.pops, method = "CG")) # control = list(maxit = 100)
opt
parse(text = "2 + 3")
parse(text = "sum(2, 3")
parse(text = "sum(2, 3)")
parse(text = "rnorm(100)")
eval(parse(text = "rnorm(100)"))
x <- data.frame(y = LETTERS[1:6], x = runif(6))
eval(parse(text = "x$y"))
eval(parse(text = "x$y=='E'"))
eval(parse(text = "x$z <- 1:6"))
x
########################################################
#
# TEST SIMULATED ANNEALING METHOD USING BASKETBALL PILOT
#
#   The objective function is to allocate seats to
#   even-numbered community areas.
#
########################################################
rm(list=ls())
#library(foreign) # This allows us to import dbf files.
setwd("~/GitHub/canopy")
source("./code/run-canopy/declare-canopy-method.r")
"%&%" <- function(...){paste(..., sep="")}
library(plyr) # Need to use join()
library(data.table) # To race against join() and other methods of merging tables for speed
require(compiler)
enableJIT(3)
#####################
# Set Run Parameters
#####################
nIter       <- 3e5
nCheckPoint <- ceiling(nIter/50) # 6e3
#############################################################
# Set Up Initialization, Objective, Neighbors and Temperature
#############################################################
load("./data/prepped/youth-to-court-data.Rda")
n.yc <- nrow(y2c)
y.u <- unique(y2c$y.Id)
c.u <- unique(y2c$c.Id)
n.y <- length(y.u)
n.c <- length(c.u)
load("./data/prepped/court-to-court-distances.Rda")
head(c2c)
y2c$w[y2c$pov == "n200_.FPL"  ] <- 1
y2c$w[y2c$pov == "n100_199FPL"] <- 2
y2c$w[y2c$pov == "n50_99FPL"  ] <- 3
y2c$w[y2c$pov == "n0_50FPL"   ] <- 4
yWgt <- unique(y2c[, c("y.Id", "w")])
yWgt
dim(y2c)
Alloc <- data.frame(c.u)
colnames(Alloc) <- "c.Id"
Alloc$s0 <- as.integer(1)
# Also break out these columns as vectors to see if their use can speed of runs of Obj()
c.u <- as.vector(c.u)
s0  <- as.vector(Alloc$s0)
# Set lower and upper bounds
vLowerBound <- as.vector(rep(0, n.c))
vUpperBound <- as.vector(rep(n.c, n.c)) # This is effectively unconstrained
headAlloc
head(Alloc)
dim(Alloc)
unique(c.u)
order(c.u)
class(c.u)
sort(c.u)
c.u[order(c.u)]
c.u
order(c.u)
?order
order(c("C", "A", "B"))
z <- c("C", "A", "B")
order(z)
system.time(m <- merge(y2c, Alloc, by="c.Id"))
dim(Alloc)
y2c_c.times.vert  <- matrix(rep(y2c$c.Id, n.c), nrow = n.yc)
dim(y2c_c.times.vert)
head(y2c_c.)
head(y2c_c.times.vert)
?rapply
s.to.yc <- array(FALSE, c(nrow(y2c), ncol(n.c)))
dim(s.to.yc)
s.to.yc <- (y2c_c.times.vert == c_y2c.times.horiz)
c_y2c.times.horiz <- matrix(rep(c.u, n.yc), nrow = n.yc, byrow=TRUE)
s.to.yc <- array(FALSE, c(nrow(y2c), ncol(n.c)))
s.to.yc <- (y2c_c.times.vert == c_y2c.times.horiz)
dim(s.to.yc)
head(s.to.yc)
s.to.yc.d <- (y2c_c.times.vert == c_y2c.times.horiz)
y2c_c.times.vert  <- matrix(rep(y2c$c.Id, n.c), nrow = n.yc)
c_y2c.times.horiz <- matrix(rep(c.u, n.yc), nrow = n.yc, byrow=TRUE)
# Declare s.to.yc as a logical matrix, to avoid typing as double
s.to.yc <- array(FALSE, c(nrow(y2c), ncol(n.c)))
# Also create a version of the matrix which is a double, since %*% casts into a double, and this may save time
s.to.yc.d <- (y2c_c.times.vert == c_y2c.times.horiz)
rm(y2c_c.times.vert, c_y2c.times.horiz)
system.time(y2c.s <- s.to.yc %*% s0)
dim(s.to.yc)
dim(s0
)
s.to.yc <- array(FALSE, c(nrow(y2c), ncol(n.c)))
dim(s.to.yc)
?array
c(nrow(y2c), ncol(n.c))
nrow(y2c)
ncol(n.c)
########################################################
#
# TEST SIMULATED ANNEALING METHOD USING BASKETBALL PILOT
#
#   The objective function is to allocate seats to
#   even-numbered community areas.
#
########################################################
rm(list=ls())
#library(foreign) # This allows us to import dbf files.
setwd("~/GitHub/canopy")
source("./code/run-canopy/declare-canopy-method.r")
"%&%" <- function(...){paste(..., sep="")}
library(plyr) # Need to use join()
library(data.table) # To race against join() and other methods of merging tables for speed
require(compiler)
enableJIT(3)
#####################
# Set Run Parameters
#####################
nIter       <- 3e5
nCheckPoint <- ceiling(nIter/50) # 6e3
#############################################################
# Set Up Initialization, Objective, Neighbors and Temperature
#############################################################
load("./data/prepped/youth-to-court-data.Rda")
n.yc <- nrow(y2c)
y.u <- unique(y2c$y.Id)
c.u <- unique(y2c$c.Id)
n.y <- length(y.u)
n.c <- length(c.u)
load("./data/prepped/court-to-court-distances.Rda")
# Determine weight for youth in objective
y2c$w[y2c$pov == "n200_.FPL"  ] <- 1
y2c$w[y2c$pov == "n100_199FPL"] <- 2
y2c$w[y2c$pov == "n50_99FPL"  ] <- 3
y2c$w[y2c$pov == "n0_50FPL"   ] <- 4
yWgt <- unique(y2c[, c("y.Id", "w")])
#-------------------------------------------#
# # # Set Initial Allocation and Counts # # #
#-------------------------------------------#
# Starting resources are equal number of staff as sites
Alloc <- data.frame(c.u)
colnames(Alloc) <- "c.Id"
Alloc$s0 <- as.integer(1)
# Also break out these columns as vectors to see if their use can speed of runs of Obj()
c.u <- as.vector(c.u)
s0  <- as.vector(Alloc$s0)
# Set lower and upper bounds
vLowerBound <- as.vector(rep(0, n.c))
vUpperBound <- as.vector(rep(n.c, n.c)) # This is effectively unconstrained
#-------------------------------------------------------------------------------#
# # # Sandbox to Test Functions to Improve Runtimes for Components of Obj() # # #
#-------------------------------------------------------------------------------#
#----
# # # 1. Compare run times for various procedures to map allocation to youth-to-court data
#----
# Try standard merging (my first instinct)
system.time(m <- merge(y2c, Alloc, by="c.Id"))
# In a test with nyc ~= 800k, nc = 60, different runs
# took 8.64, 5.54, 3.68, 4.43 seconds (before enableJIT(3))
# Try a join() using plyr instead... seems to work a bit faster
system.time(m <- join(y2c, Alloc, by="c.Id"))
# In a test with nyc ~= 800k, nc = 60, different runs
# took 4.79, 3.87, 6.71, 3.82, 4.68 seconds (before enableJIT(3))
# Generate indicator function to create mapping using inner products.
# (The indicator matrix requires a huge chunk of memory, but may speed operation)
# Prepare the matrix, which should be n.yc by n.c
y2c_c.times.vert  <- matrix(rep(y2c$c.Id, n.c), nrow = n.yc)
c_y2c.times.horiz <- matrix(rep(c.u, n.yc), nrow = n.yc, byrow=TRUE)
# Declare s.to.yc as a logical matrix, to avoid typing as double
s.to.yc <- array(FALSE, c(nrow(y2c), ncol(n.c)))
# Also create a version of the matrix which is a double, since %*% casts into a double, and this may save time
s.to.yc.d <- (y2c_c.times.vert == c_y2c.times.horiz)
rm(y2c_c.times.vert, c_y2c.times.horiz)
?data.table
y2c.dt <- data.table(y2c, key="c.Id")
s.dt <- data.table(Alloc, key="c.Id")
system.time(y2c.s.dt <- merge(y2c.dt, s.dt))
s.dt
system.time(y2c.s.dt <- merge(y2c.dt, s.dt))
y2c <- within(y2c, {
e <- rnorm(n.yc)
xb <- 1.5 + (-1.0)*d + (-2.0)*d*cr + 1.5*e # indirect utility, except for staff allocation, which gets added in at each step
})
y2c <- data.table(y2c)
# Preallocate components of y2c.o which will be added in
y2c.o <- within(y2c, {
s <- 1
e.Xbs <- exp(xb + 0.5*s)
eXb <- 0
Sum.eXb <- 0
p <- 0
})
y2c.o <- data.table(y2c.o)
hist(y2c.o$xb) # if properly tuned, should have decent density both above and below 0
y.pr.sums <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("p")]
Obj <- function(a) {
# Merge in staff allocation data for probability calculations
# Get youth probability by dividing value by sum of values by y
colnames(a) <- c("c.Id", "s") # We're naming this to generic "s" since many states may be passed into this function
y2c.o <- merge(y2c, a, by="c.Id")
y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s)) # add staff allocations to indirect utility and raise as exponent
# Generate function value for each y2c combination
Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")]
y2c.o <- merge(y2c.o, Sum.eXbs, by="y.Id")
y2c.o$p <- y2c.o$eXbs / (1 + y2c.o$Sum.eXbs)
# The 1 represents the normalized value of the alternative Vi0, since: 1 = exp(0)
#Sum probability that each youth plays ball
Sum.p <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("p")]
# Merge in youth objective weights and score
yPrPov <- merge(Sum.p, yWgt, by="y.Id")
score  <- t(as.vector(yPrPov$p)) %*% as.vector(yPrPov$w)
#hist(Sum.p$TotPr)
return(score)
}
init <- data.frame(c.u, 1)
init
system.time({
for (i in 1:1000){
Obj(init)
}
})
enableJIT(0)
system.time({
for (i in 1:1000){
Obj(init)
}
})
a<-init
colnames(a) <- c("c.Id", "s") # We're naming this to generic "s" since many states may be passed into this function
y2c.o <- merge(y2c, a, by="c.Id")
y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s)) # add staff allocations to indirect utility and raise as exponent
# Generate function value for each y2c combination
Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")]
y2c.o <- merge(y2c.o, Sum.eXbs, by="y.Id")
y2c.o$p <- y2c.o$eXbs / (1 + y2c.o$Sum.eXbs)
head(y2c.o)
head(Sum.eXbs)
y2c.o$p <- y2c.o$eXbs / (1 + y2c.o$e.Xbs)
Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")]
y2c.o <- merge(y2c.o, Sum.eXbs, by="y.Id")
colnames(a) <- c("c.Id", "s") # We're naming this to generic "s" since many states may be passed into this function
y2c.o <- merge(y2c, a, by="c.Id")
y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s)) # add staff allocations to indirect utility and raise as exponent
Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")]
y2c.o <- merge(y2c.o, Sum.eXbs, by="y.Id")
y2c.o$p <- y2c.o$eXbs / (1 + y2c.o$e.Xbs)
head(y2c.o)
y2c.o$p <- y2c.o$e.Xbs.x / (1 + y2c.o$e.Xbs.y)
Obj <- function(a) {
# Merge in staff allocation data for probability calculations
# Get youth probability by dividing value by sum of values by y
colnames(a) <- c("c.Id", "s") # We're naming this to generic "s" since many states may be passed into this function
y2c.o <- merge(y2c, a, by="c.Id")
y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s)) # add staff allocations to indirect utility and raise as exponent
# Generate function value for each y2c combination
Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")]
y2c.o <- merge(y2c.o, Sum.eXbs, by="y.Id")
y2c.o$p <- y2c.o$e.Xbs.x / (1 + y2c.o$e.Xbs.y)
# The 1 represents the normalized value of the alternative Vi0, since: 1 = exp(0)
#Sum probability that each youth plays ball
Sum.p <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("p")]
# Merge in youth objective weights and score
yPrPov <- merge(Sum.p, yWgt, by="y.Id")
score  <- t(as.vector(yPrPov$p)) %*% as.vector(yPrPov$w)
#hist(Sum.p$TotPr)
return(score)
}
init <- data.frame(c.u, 1)
system.time({
for (i in 1:1000){
Obj(init)
}
})
system.time(Obj(init))
system.time(Obj(init))
system.time(Obj(init))
system.time(Obj(init))
system.time(Obj(init))
system.time(y2c.o <- merge(y2c, a, by="c.Id"))
system.time(y2c.o <- merge(y2c, a, by="c.Id"))
system.time(y2c.o <- merge(y2c, a, by="c.Id"))
system.time(y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s))) # add staff allocations to indirect utility and raise as exponent
system.time(y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s))) # add staff allocations to indirect utility and raise as exponent
system.time(y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s))) # add staff allocations to indirect utility and raise as exponent
system.time(es y2c.o$e.Xbs*exp(0.5*s))
system.time(es <- y2c.o$e.Xbs*exp(0.5*s))
system.time(es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s))
system.time(es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s))
system.time(y2c.o$es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s))
system.time(y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s))) # add staff allocations to indirect utility and raise as exponent
system.time(y2c.o$es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s))
system.time(y2c.o <- within(y2c.o, e.Xbs <- exp(xb + 0.5*s))) # add staff allocations to indirect utility and raise as exponent
system.time(y2c.o$es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s))
system.time(y2c.o$es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s)) # add staff allocations to indirect utility and raise as exponent
system.time(y2c.o$es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s)) # add staff allocations to indirect utility and raise as exponent
system.time(y2c.o$es <- y2c.o$e.Xbs*exp(0.5*y2c.o$s)) # add staff allocations to indirect utility and raise as exponent
system.time(Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")])
system.time(Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")])
system.time(Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")])
?sweep
m <- matrix(1:20, nrow = 10)
m
sweep(m, 2, mean)
sweep(m, 2, mean, "/")
sweep(m, 2, mean)
sweep(m, 1, mean)
sweep(data.frame(m), 1, mean)
m
sweep(m, 2, mean)
sweep(m, 2, sum)
A <- array(1:24, dim = 4:2)
sweep(A, 2, mean)
A
sweep(A, 1, 5)
sweep(A, 1, 5, "/")
A <- array(1:24, dim = c(12,2))
A
class(A)
sweep(A, 1, sum)
sweep(A, 1, mean)
sweep(A, 2, mean)
sweep(data.matrix(A), 2, mean)
attitude
class(attitude)
sweep(attitude, 2, mean)
med.att <- apply(attitude, 2, median)
sweep(data.matrix(attitude), 2, med.att)
med.att <- apply(attitude, 2, median)
sweep(attitude, 2, med.att)
med.att
system.time(Sum.eXbs <- y2c.o[, lapply(.SD, sum), by = y.Id, .SDcols=c("e.Xbs")])
